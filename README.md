# neural_nets_with_numpy

Practicing Neural network fundamentals by implementing everything in python and numpy. 

List of things:   
    **-- Layers**:  
           -- Linear (done)  
           -- Conv2D (todo)  
           -- DepthWiseConv2D (todo)   
           -- Conv1D (todo)   
           -- Conv3D (todo)  
           -- LSTM (todo)  
    **-- Normalizations**:  
           -- BatchNorm (todo)  
           -- InstanceNorm (todo)  
           -- LayerNorm (todo)  
           -- GroupNorm (todo)  
    **-- Activations**:  
           -- ReLU (done)  
           -- Sigmoid (done)  
           -- Tanh (done)  
           -- SoftMax (todo)  
           -- SoftPlus (todo)  
           -- Swish (todo)  
           -- LeakyReLU (todo)  
           -- Parametric ReLU (todo)  
           -- ArcTan (todo)  
    **-- Loss Functions**:  
           -- MAE (done)  
           -- MSE (done)  
           -- Binary Cross Entropy (todo)   
           -- KL-divergence (todo)  
